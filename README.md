# American Sign Language (ASL) Gesture Recognition

Built and trained three deep learning models with different architectures and parameters. The training dataset contains 87,000 images which are 200 x 200 RGB pixels. Developed a full-stack website that offers real-time ASL gesture recognition, dynamically displays the recognized signs as text, and integrates a Text-to-Speech API to verbalize the text.

|      File Name       | Description                                                  |
| :------------------: | ------------------------------------------------------------ |
| **Train_models.py**  | Train different models with different parameters.            |
| **Test_models.py**   | Testing models on unseen data.                               |
|    **network.py**    | Load the parameter file and run the model.                   |
|    **camera.py**     | Process the video from the camera and convert text to audio  |
|    **index.py**      | Launch the web application                                   |
|      Templates       | Store front-end .HTML file.                                  |
|        Static        | Store front-end background picture.                          |

